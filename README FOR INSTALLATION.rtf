{\rtf1\ansi\ansicpg1252\cocoartf1671
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Oblique;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 README FOR INSTALLATION:\
\
This project uses the AudioKit cocoapod, but the pod contents are too large to supply in the code.\
Therefore, the pods will need to be built. Ensure CocoaPods is installed on the target machine.\
\
Using the terminal, CD to the directory of this readme file /MusiciansToolkit. The Podfile should be in this folder.\
\
Run the following command:\
\

\f1\i pod install\
\

\f0\i0 Now, open the MusiciansToolkit.xcworkspace file. Be sure to open the xcworkspace file NOT the xcodeproj file.\
\
Project notes:\
So far implemented is the tuner, chord bank, metronome, and most of the recorder. The scale bank was put on hold as it is programmatically the same as the chord bank, but requires just a lot of mindless busy work to get samples of all of the 12*4 = 48 scales and their photos. Therefore, more emphasis was put on the more hefty programming parts of the application, especially the recorder.\
\
Main takeaway so far: audio in Swift is tough!! Especially with multiple units (metronome, tuner, recorder, etc.) that all need to play, record, and analyze sound. Sometimes sounds need to be played over top of each other (metronome while recording, etc.). A dedicated file for this (Audio.swift) was used to take care of this. Still I face many huge learning hurdles. For example, I currently can\'92t figure out a way to simultaneously record the microphone node and show its waveform, as a node can only be \'93tapped\'94 by one audio device at a time. Surely I will find a way around this soon enough.\
\
Hope you enjoy! It\'92s been a great learning experience thus far.}